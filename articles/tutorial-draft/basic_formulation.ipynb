{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial of Deep learning 02: Basic formulation (draft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. [Bayes 公式](probability_theory.html)\n",
    "\n",
    "$$p(y|x) = {p(x|y)p(y)\\over p(x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数学推导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ">问题： 已知经验数据 $S＝\\{(x_1, y_1),(x_2, y_2),\\dots,(x_n, y_n)\\}$，\n",
    "若此后给定一个新的 $x$ 怎样预测它对应的 $y$ 值？\n",
    "\n",
    "我们把 $[x_1, x_2,\\dots,x_n]$ 和 $[y_1, y_2,\\dots,y_n]$ 分别看做是$n$维随机变量 $\\mathcal{X}\\equiv[X_1,\\cdots X_n]$ 和 $\\mathcal{Y}\\equiv[Y_1,\\cdots Y_n]$ 的一次采样结果 (（注意：各个 $X_i, Y_i$ 本身也可以是多维的)\n",
    "\n",
    "基于**i.i.d** (independent, identical distribution)假设, 我们认为描述$\\mathcal{X}, \\mathcal{Y}$ 的**“真实”**概率分布 $\\mathcal{Q(X,Y)}$ 满足：\n",
    "\n",
    "$$\\mathcal{Q(X,Y)}\\equiv \\prod_i q(X_i, Y_i)$$\n",
    "\n",
    "不难证明，此时我们也有\n",
    "\n",
    "$$\\mathcal{Q(Y|X)}\\equiv \\prod_i q(Y_i|X_i)$$\n",
    "\n",
    "而若给定一个新的$x$, 它对应的$y$预测值，由如下期望值决定：\n",
    "\n",
    "$$\\langle y\\rangle = \\int y * q(y|x){\\rm d}y\\qquad\\text{(1)}$$\n",
    "\n",
    "我们试图用某种理论模型 $\\mathcal{P(Y|X,\\theta)}\\equiv \\prod\\limits_i p(Y_i|X_i,\\theta)$ 来逼近 $\\mathcal{Q(Y|X)}$，即\n",
    "\n",
    "$$\\mathcal{P(Y|X,\\theta)}\\equiv \\prod\\limits_i p(Y_i|X_i,\\theta)\\rightarrow\\mathcal{Q(Y|X)}\\equiv \\prod_i q(Y_i|X_i)\\qquad\\text{(2)}$$\n",
    "\n",
    "显然当上述条件满足, 可用$p(y|x,\\theta)$ 来近似 (1)式中的 $q(y|x)$，\n",
    "\n",
    "\n",
    "定义 $$\\mathcal{P(\\theta|X,Y)}\\equiv\\prod_i p(\\theta|X_i, Y_i)$$  \n",
    "\n",
    "它表示在选定理论模型下，若已知$\\{X_i\\},\\{Y_i\\}$, 那么 $\\theta$ 的取值概率是多少。\n",
    "\n",
    "### Bayes inference\n",
    "\n",
    "\n",
    "\n",
    "由于我们已知一组经验数据$\\{(x_1, y_1),(x_2, y_2),\\dots,(x_n, y_n)\\}$ ，因此在已知的信息条件下，$\\theta$的概率为\n",
    "\n",
    "$$\\mathcal{P(\\theta|\\{x_i\\},\\{y_i\\})}\\equiv\\prod_i p(\\theta|x_i, y_i)= \\prod_i \\left({1\\over C_i}p(y_i|x_i, \\theta)p(\\theta)\\right)\\qquad\\text{(3)}$$\n",
    "\n",
    "其中$C_i$ 是归一化系数，定义为$$\n",
    "C_i=\\int p(y_i|x_i, \\theta)p(\\theta) {\\rm d}\\theta \n",
    "$$\n",
    "\n",
    "因此，用 $p(y|x,\\theta)$ 近似 $q(y|x)$，同时考虑到 $\\theta$ 本身的概率性，(1)式可化为：\n",
    "\n",
    "$$\\langle y\\rangle \\approx \\int y * p(y|x,\\theta)\\mathcal{P(\\theta|\\{x_i\\},\\{y_i\\})}{\\rm d}y{\\rm d}\\theta = {1\\over C}\\int y * p(y|x,\\theta)\\prod_i\\left[p(y_i|x_i, \\theta)p(\\theta)\\right]{\\rm d}y{\\rm d}\\theta\\;\\text{(4)}$$\n",
    "\n",
    "其中 $C\\equiv\\prod_i C_i$ 是整体的归一化系数, $p(\\theta)$ 是选定的 prior distribution. 一般来说，我们在选择$p(\\theta)$时应当考虑以下几个方面：\n",
    "\n",
    "- **能够反映我们关于$\\theta$ 的 naive belief **\n",
    "- **数学表达式具有较好的拟合能力（capacity）** \n",
    "- **数学表达式在推解析导中较容易计算 （详见概率论中[conjugate prior](probability_theory.html)的概念）**\n",
    "\n",
    "**注意: 这个公式允许我们在没有“模型训练”的前提下，就可以直接进行预测** ， 预测的好坏取决于我们选择的“泛型”$p(y|x,\\theta)$ 函数形式与实际问题的匹配程度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### “鞍点”近似 (MAP, maximum  posteriori)\n",
    "\n",
    "实际应用中，（4）的数值计算过于困难。为简化计算，我们进一步引入“鞍点”近似，即我们仅考虑（3）中 $\\theta^*$ 的贡献，其中 $\\theta^*$ 对应 $\\mathcal{P(\\theta|\\{x_i\\},\\{y_i\\})}$ 的峰值位置，即\n",
    "\n",
    "\n",
    "$$ \n",
    "\\begin{align}\\theta^* &=\\mathop{\\rm argmax}\\limits_\\theta \\mathcal{P(\\theta|\\{x_i\\},\\{y_i\\})} = \\mathop{\\rm argmax}\\limits_\\theta{1\\over n}\\log \\mathcal{P(\\theta|\\{x_i\\},\\{y_i\\})}\\\\\n",
    "&=\\mathop{\\rm argmax}\\limits_\\theta {1\\over n} \\log\\prod\\limits_{i=1}^n\\left(p(y_i|x_i,\\theta)p(\\theta)\\right)\\\\\n",
    "&=\\mathop{\\rm argmax}\\limits_\\theta \\left[S(\\theta) + \\log p(\\theta)\\right]\\\\\n",
    "S(\\theta) &\\equiv {1\\over n}\\sum_{i=1}^n \\log p(y_i|x_i,\\theta)\\\\\n",
    "\\end{align}\\qquad\\text{(5)}$$\n",
    "\n",
    "其中 $S(\\theta)$ 是 Maximum Likelihood 项, $\\log p(\\theta)$ 项相当于“正则化”\n",
    "\n",
    "\n",
    "$$ \\langle y\\rangle \\approx \\int y * p(y|x,\\theta)*\\delta(\\theta-\\theta^*){\\rm d}y{\\rm d}\\theta = \\int y * p(y|x,\\theta^*) {\\rm d}y \\qquad\\text{(6)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 重要关系\n",
    "\n",
    "\n",
    "### 与正则化的关系\n",
    "\n",
    "$\\log p(\\theta)$ 相当于正则化项，例如：取 $p(\\theta)$ 为正态分布，则得到 Ridge 正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 与  MLE的关系 （Maximum Likelihood Estimation） \n",
    "当 $p(\\theta)$ 是一个 trivial 的 **uniform** 分布时，有 \n",
    "$$\\mathop{\\rm argmax}\\limits_\\theta\\mathcal{P}(\\theta|\\{x_i\\},\\{y_i\\}) = \n",
    "\\mathop{\\rm argmax}\\limits_\\theta  \\mathcal{P}(\\{y_i\\}|\\{x_i\\},\\theta) $$\n",
    "\n",
    "即，**没有正则化项时，MAP “退化为” MLE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 与KL散度的关系 （Kullback–Leibler divergence）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathop{\\rm argmax}\\limits_\\theta S(\\theta)$ 可视为一个KL divergence项:\n",
    "\n",
    "定义“经验”概率分布为 $q_e\\equiv {1\\over n}\\sum_i\\delta(x-x_i)\\delta(y-y_i)$ 则：\n",
    "\n",
    "$$\\begin{align}\\mathop{\\rm argmax}\\limits_\\theta S(\\theta) &= \\mathop{\\rm argmax}\\limits_\\theta \\int{\\rm d}x{\\rm d}y q_e(y|x)p(y|x,\\theta)\\\\\n",
    "&=\\mathop{\\rm argmin}\\limits_\\theta \\int{\\rm d}x{\\rm d}y q_e(y|x)\\left(q_e(y|x)-p(y|x,\\theta)\\right)\\\\\n",
    "&=\\mathop{\\rm argmin}\\limits_\\theta KL\\left(q_e\\|p\\right)\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 与MSE 的关系 （如：线性回归）\n",
    "\n",
    "同样基于i.i.d.假设，我们认为单次采样的model分布具有如下高斯形式：\n",
    "\n",
    "$$p(y|x,\\theta)={1\\over \\sqrt{2\\pi}\\sigma}\\exp\\left[-{\\left(f(x,\\theta)-y\\right)^2\\over 2\\sigma^2}\\right]$$\n",
    "\n",
    "则 $$\\theta^* ={\\rm argmin} S_\\theta = {\\rm argmin} \\left(\\sum\\limits_{i=1}^n{1\\over n}\\left\\|f(x_i,\\theta)-y_i\\right\\|^2\\right)$$\n",
    "\n",
    "这个结论和前文model first“决定论”框架中基于 minimize training error $R_{\\rm emp}(\\alpha)$ 的形式一致\n",
    "\n",
    "求得最优参数$\\theta^*$ 后，给定输入$x$，预测值$y$ 为：\n",
    "\n",
    "$$\\langle y\\rangle = \\int y {1\\over \\sqrt{2\\pi}\\sigma}\\exp\\left[-{\\left(f(x,\\theta^*)-y\\right)^2\\over 2\\sigma^2}\\right] {\\rm d} y = f(x,\\theta^*)$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
